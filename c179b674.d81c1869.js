(window.webpackJsonp=window.webpackJsonp||[]).push([[94],{149:function(e,t,i){"use strict";i.r(t),i.d(t,"frontMatter",(function(){return r})),i.d(t,"metadata",(function(){return o})),i.d(t,"rightToc",(function(){return s})),i.d(t,"default",(function(){return u}));var a=i(2),n=(i(0),i(181));const r={id:"meaningful-availability",title:"Meaningful Availability"},o={unversionedId:"sre/availability/meaningful-availability",id:"sre/availability/meaningful-availability",isDocsHomePage:!1,title:"Meaningful Availability",description:"Link to Article",source:"@site/docs/sre/availability/meaningful-availability.md",slug:"/sre/availability/meaningful-availability",permalink:"/docs/sre/availability/meaningful-availability",version:"current",sidebar:"availability"},s=[{value:"Abstract",id:"abstract",children:[]},{value:"Related Work",id:"related-work",children:[]},{value:"Motivation",id:"motivation",children:[{value:"Time based availability metrics",id:"time-based-availability-metrics",children:[]},{value:"Count-based availability metrics",id:"count-based-availability-metrics",children:[]},{value:"Probes",id:"probes",children:[]},{value:"Actionable metrics",id:"actionable-metrics",children:[]}]},{value:"Proportional and Meaningful Availability: User-Uptime",id:"proportional-and-meaningful-availability-user-uptime",children:[{value:"Events and Durations",id:"events-and-durations",children:[]},{value:"Challenges with User Uptime",id:"challenges-with-user-uptime",children:[]}]},{value:"Actionable Availability: Windowed User Uptime",id:"actionable-availability-windowed-user-uptime",children:[{value:"Calculating Windowed User Uptime",id:"calculating-windowed-user-uptime",children:[]},{value:"Monotonicity with Integer Multiple-Sized Windows",id:"monotonicity-with-integer-multiple-sized-windows",children:[]},{value:"Monotonicity in the General Case",id:"monotonicity-in-the-general-case",children:[]}]},{value:"Evaluation",id:"evaluation",children:[{value:"Availability Due to Hyperactive Users",id:"availability-due-to-hyperactive-users",children:[]},{value:"Availability and Hyper Active Retries",id:"availability-and-hyper-active-retries",children:[]},{value:"Quantifying Impact of Outages",id:"quantifying-impact-of-outages",children:[]},{value:"Combining User Uptime and Success Ratio",id:"combining-user-uptime-and-success-ratio",children:[]},{value:"Windowed Uptime Causes Burstiness of Unavailability",id:"windowed-uptime-causes-burstiness-of-unavailability",children:[]}]},{value:"Applicability of Windowed User Uptime",id:"applicability-of-windowed-user-uptime",children:[]},{value:"Conclusion",id:"conclusion",children:[]}],l={rightToc:s};function u({components:e,...t}){return Object(n.b)("wrapper",Object(a.a)({},l,t,{components:e,mdxType:"MDXLayout"}),Object(n.b)("p",null,Object(n.b)("a",Object(a.a)({parentName:"p"},{href:"https://www.usenix.org/system/files/nsdi20spring_hauer_prepub.pdf"}),"Link to Article"),"  "),Object(n.b)("h2",{id:"abstract"},"Abstract"),Object(n.b)("p",null,"High availability is critical for applications because without it, users cannot rely on it for important work."),Object(n.b)("h2",{id:"related-work"},"Related Work"),Object(n.b)("p",null,"Three desirable properties of an availability metric: meaningful, proportional, and actionable."),Object(n.b)("h2",{id:"motivation"},"Motivation"),Object(n.b)("p",null,"Availability is the ability of a service to perform its required function at an agreed instant or over an agreed period of time. At a high level, all availability metrics have the following form:"),Object(n.b)("p",null,"availability = good service / total demanded service"),Object(n.b)("p",null,"Availability metrics are valuable for users because they tell them whether or not a service is suitable for their use case.",Object(n.b)("br",{parentName:"p"}),"\n","Availability metrics are valuable for developers because they help prioritize their work to improve the system.  "),Object(n.b)("p",null,"Proportional metrics enable developers to quantify the benefit of an incremental improvement.",Object(n.b)("br",{parentName:"p"}),"\n","Actionable metrics enable developers to zero in on episodes of worst availability and find problems that need addressing.  "),Object(n.b)("h3",{id:"time-based-availability-metrics"},"Time based availability metrics"),Object(n.b)("p",null,"availability = MTTF / (MTTF + MTTR)",Object(n.b)("br",{parentName:"p"}),"\n","Where MTTF = mean-time-to-failure and MTTR = mean-time-to-recovery"),Object(n.b)("p",null,"This measure is based on the duration of the system being up or down."),Object(n.b)("p",null,"uptime = good service",Object(n.b)("br",{parentName:"p"}),"\n","downtime = bad service  "),Object(n.b)("p",null,"availability = uptime / (uptime + downtime)"),Object(n.b)("p",null,"Commonly used time-based availability metrics:"),Object(n.b)("ol",null,Object(n.b)("li",{parentName:"ol"},"Are not proportional to the severity of the system's unavailability (a downtime with 100% failure rate weighs the same as one with 10% failure rate)"),Object(n.b)("li",{parentName:"ol"},"Are not proportional to the number of affected users (a downtime at night has the same weight as downtime during a peak period)"),Object(n.b)("li",{parentName:"ol"},"Are not actionable because they do not, in themselves, provide developers guidance into the sources of failures"),Object(n.b)("li",{parentName:"ol"},"Are not meaningful in they rely on arbitrary thresholds or manual judgments")),Object(n.b)("h3",{id:"count-based-availability-metrics"},"Count-based availability metrics"),Object(n.b)("p",null,"Success ratio is the ratio of successful requests to total requests. Since success-ratio does not use a threshold, it is more proportional than commonly used time-based metrics.  "),Object(n.b)("p",null,"Success ratio is as an availability measure is popular because it is easy to implement and is a reasonable measure.  "),Object(n.b)("p",null,"Count-based (success-ratio) availability metrics:"),Object(n.b)("ol",null,Object(n.b)("li",{parentName:"ol"},"Are not meaningful in they are not based on time"),Object(n.b)("li",{parentName:"ol"},"Are biased by highly active users"),Object(n.b)("li",{parentName:"ol"},"Are biased because of different client behavior during outages")),Object(n.b)("h3",{id:"probes"},"Probes"),Object(n.b)("p",null,"Synthetic probes may mitigate some of the shortcomings of success-ratio."),Object(n.b)("p",null,"A metric which uses synthetic probes may not be representative of real-user experience"),Object(n.b)("p",null,"Availability metrics based on synthetic probes:"),Object(n.b)("ol",null,Object(n.b)("li",{parentName:"ol"},"Are not representative of user activity"),Object(n.b)("li",{parentName:"ol"},"Are not proportional to what users experience")),Object(n.b)("h3",{id:"actionable-metrics"},"Actionable metrics"),Object(n.b)("p",null,"Availability metrics mentioned above represent different points in the tradeoffs between proportional and meaningful. They all have a similar weakness though: actionable. A single number with a reporting period does not allow enough insight into the source or shape of unavailability."),Object(n.b)("h2",{id:"proportional-and-meaningful-availability-user-uptime"},"Proportional and Meaningful Availability: User-Uptime"),Object(n.b)("p",null,"As discussed, prior metrics mentioned for availability are not meaningful or proportional. This equation satisfies both proportionality and meaningfulness:"),Object(n.b)("p",null,"user-uptime = ",Object(n.b)("a",Object(a.a)({parentName:"p"},{href:"https://en.wikipedia.org/wiki/Summation"}),"summation")," uptime per user / ",Object(n.b)("a",Object(a.a)({parentName:"p"},{href:"https://en.wikipedia.org/wiki/Summation"}),"summation")," (uptime per user + downtime per user)  "),Object(n.b)("p",null,"The calculation of this metric is not straightforward as it requires the definition of uptime and downtime per user.  "),Object(n.b)("h3",{id:"events-and-durations"},"Events and Durations"),Object(n.b)("p",null,"Use user requests as probes. A user's perception of a system being up or down depends on the response they receive when interacting with it. Successful == up, unsuccessful == down  "),Object(n.b)("p",null,"If there is ",Object(n.b)("em",{parentName:"p"},"any")," chance that a user may perceive a failure, consider it as a failure.  "),Object(n.b)("h3",{id:"challenges-with-user-uptime"},"Challenges with User Uptime"),Object(n.b)("p",null,"How would you label duration as up or down?",Object(n.b)("br",{parentName:"p"}),"\n","How do you address if users are active or not?  "),Object(n.b)("h4",{id:"labeling-durations"},"Labeling Durations"),Object(n.b)("p",null,"If back to back events differ, there are 3 choices for labels:"),Object(n.b)("ol",null,Object(n.b)("li",{parentName:"ol"},"After a successful (failed) operation, assume the system is up (down) until the user sees evidence to indicate otherwise"),Object(n.b)("li",{parentName:"ol"},"Before a successful (failed) operation, assume the system is up (down) until the previous event"),Object(n.b)("li",{parentName:"ol"},"Split the duration between events. Half the time us uptime and half the time is downtime")),Object(n.b)("h4",{id:"active-and-inactive-periods"},"Active and Inactive Periods"),Object(n.b)("p",null,"Cutoff Duration - if a user has been inactive for more than the specified (cutoff) duration, consider the user as inactive and stop recording uptime and downtime for that user.  "),Object(n.b)("p",null,"Definition (uptime, downtime): A segment between two consecutive events originating from the same user is:"),Object(n.b)("ul",null,Object(n.b)("li",{parentName:"ul"},"inactive if the two events are further apart than the cutoff duration"),Object(n.b)("li",{parentName:"ul"},"uptime if the first of the two events was successful"),Object(n.b)("li",{parentName:"ul"},"downtime if the first of the two events was unsuccessful (failed)")),Object(n.b)("p",null,"For each user and a measurement period of interest, uptime is the sum of lengths of uptime segments and downtime is the sum of lengths of downtime segments."),Object(n.b)("h2",{id:"actionable-availability-windowed-user-uptime"},"Actionable Availability: Windowed User Uptime"),Object(n.b)("p",null,"Monthly or quarterly availability reporting does not distinguish between a system that routinely fails a small percentage of requests from a system where failures are rare, but experience longer outages.",Object(n.b)("br",{parentName:"p"}),"\n","To distinguish long outages from shorter, more frequent outages, the timescale of outages must be looked at.",Object(n.b)("br",{parentName:"p"}),"\n","Windowed User Uptime addresses that by combining information from all timescales simultaneously.  "),Object(n.b)("h3",{id:"calculating-windowed-user-uptime"},"Calculating Windowed User Uptime"),Object(n.b)("p",null,"Windowed User Uptime iterates over all time windows fully included in the period of interest and it computes availability score for each window size. The score for a window size w is the availability of the ",Object(n.b)("em",{parentName:"p"},"worst")," window size w in the period of interest. Availability for a particular window from t1 to t2 is calculated as follows:  "),Object(n.b)("p",null,"A(t1,t2) = good service between t1 and t2 / total service between t1 and t2"),Object(n.b)("p",null,"To obtain the score for a window size w, enumerate all windows of duration w and compute the availability for each of them and take the lowest value. The result is a score for each window size. This score is the Minimal Cumulative Ratio (MCR).  "),Object(n.b)("p",null,"MCR = Minimal Cumulative Ratio"),Object(n.b)("p",null,"MCR picks the worst availability for each window size because that is the window that had the most impact on overall availability.  "),Object(n.b)("h3",{id:"monotonicity-with-integer-multiple-sized-windows"},Object(n.b)("a",Object(a.a)({parentName:"h3"},{href:"https://en.wikipedia.org/wiki/Monotonic_function"}),"Monotonicity")," with Integer Multiple-Sized Windows"),Object(n.b)("p",null,"Expect larger windows to have better availability.  "),Object(n.b)("h3",{id:"monotonicity-in-the-general-case"},Object(n.b)("a",Object(a.a)({parentName:"h3"},{href:"https://en.wikipedia.org/wiki/Monotonic_function"}),"Monotonicity")," in the General Case"),Object(n.b)("p",null,"The worst availability of a day is always better than the worst availability of an hour or of a minute.  "),Object(n.b)("h2",{id:"evaluation"},"Evaluation"),Object(n.b)("h3",{id:"availability-due-to-hyperactive-users"},"Availability Due to Hyperactive Users"),Object(n.b)("p",null,"Bias due to hyper active users can negatively affect success-ratio.",Object(n.b)("br",{parentName:"p"}),"\n","When this bias occurs, success-ratio can mislead us towards thinking that an incident is much more or much less severe than it actually is.  "),Object(n.b)("h3",{id:"availability-and-hyper-active-retries"},"Availability and Hyper Active Retries"),Object(n.b)("p",null,"Retries can drive success ratio down even though only a small number of users are impacted.",Object(n.b)("br",{parentName:"p"}),"\n","Users (and the clients they use) may behave differently during incidents than during normal operations.  "),Object(n.b)("ul",null,Object(n.b)("li",{parentName:"ul"},"Clients may make many more requests during incidents or they may just decide to give up on the system and try few hours later. In both cases, success-ratio over or under estimates the magnitude of an outage while user-uptime matches user perception.")),Object(n.b)("h3",{id:"quantifying-impact-of-outages"},"Quantifying Impact of Outages"),Object(n.b)("p",null,"When using success ratio, quantifying the impact of an outage is difficult because it is not based on time.",Object(n.b)("br",{parentName:"p"}),"\n","Seconds of downtime, which we compute as part of user uptime, provides more insight. From there we see the minutes of downtime that our users experience.  "),Object(n.b)("h3",{id:"combining-user-uptime-and-success-ratio"},"Combining User Uptime and Success Ratio"),Object(n.b)("p",null,"Sometimes, combining user-uptime with success-ratio yields valuable insights.  "),Object(n.b)("h3",{id:"windowed-uptime-causes-burstiness-of-unavailability"},"Windowed Uptime Causes Burstiness of Unavailability"),Object(n.b)("p",null,"When looking at availability metrics aggregated over longer periods of time, it is difficult to see short periods of poor availability.",Object(n.b)("br",{parentName:"p"}),"\n","Teams can use windowed user uptime to identify root-cause and then fix the sources of these shorter episodes, improving overall availability.  "),Object(n.b)("h2",{id:"applicability-of-windowed-user-uptime"},"Applicability of Windowed User Uptime"),Object(n.b)("p",null,"To calculate windowed user-uptime, fine-grained logs of individual user operations are required. These logs must include a key that enables chaining together operations for each user, the timestamp of the operation, and the status of each operation (success or failure)."),Object(n.b)("p",null,"In the simplest case, retaining the cumulative count of up and down minutes for each minute is needed to calculate windowed user-uptime over any time duration.  "),Object(n.b)("h2",{id:"conclusion"},"Conclusion"),Object(n.b)("p",null,"User Uptime combines the advantages of per-user aggregation with those of using a time-based availability measure. "),Object(n.b)("p",null,"User Uptime avoids multiple kinds of bias: hyper-active users contribute similarly to the metric as regular users, and even behavioral changes during an outage result in a proportional and meaningful measurement that in many cases is even more precise than success-ratio.  "),Object(n.b)("p",null,"windowed availability allows for the study of multiple time-scales from single minutes to a full quarter in an easy to understand graph.  "))}u.isMDXComponent=!0},181:function(e,t,i){"use strict";i.d(t,"a",(function(){return b})),i.d(t,"b",(function(){return m}));var a=i(0),n=i.n(a);function r(e,t,i){return t in e?Object.defineProperty(e,t,{value:i,enumerable:!0,configurable:!0,writable:!0}):e[t]=i,e}function o(e,t){var i=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),i.push.apply(i,a)}return i}function s(e){for(var t=1;t<arguments.length;t++){var i=null!=arguments[t]?arguments[t]:{};t%2?o(Object(i),!0).forEach((function(t){r(e,t,i[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(i)):o(Object(i)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(i,t))}))}return e}function l(e,t){if(null==e)return{};var i,a,n=function(e,t){if(null==e)return{};var i,a,n={},r=Object.keys(e);for(a=0;a<r.length;a++)i=r[a],t.indexOf(i)>=0||(n[i]=e[i]);return n}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)i=r[a],t.indexOf(i)>=0||Object.prototype.propertyIsEnumerable.call(e,i)&&(n[i]=e[i])}return n}var u=n.a.createContext({}),c=function(e){var t=n.a.useContext(u),i=t;return e&&(i="function"==typeof e?e(t):s(s({},t),e)),i},b=function(e){var t=c(e.components);return n.a.createElement(u.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return n.a.createElement(n.a.Fragment,{},t)}},p=n.a.forwardRef((function(e,t){var i=e.components,a=e.mdxType,r=e.originalType,o=e.parentName,u=l(e,["components","mdxType","originalType","parentName"]),b=c(i),p=a,m=b["".concat(o,".").concat(p)]||b[p]||d[p]||r;return i?n.a.createElement(m,s(s({ref:t},u),{},{components:i})):n.a.createElement(m,s({ref:t},u))}));function m(e,t){var i=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var r=i.length,o=new Array(r);o[0]=p;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:a,o[1]=s;for(var u=2;u<r;u++)o[u]=i[u];return n.a.createElement.apply(null,o)}return n.a.createElement.apply(null,i)}p.displayName="MDXCreateElement"}}]);